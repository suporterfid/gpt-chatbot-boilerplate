# Prometheus Alert Rules for GPT Chatbot

groups:
  - name: chatbot_alerts
    interval: 30s
    rules:
      # High job failure rate
      - alert: HighJobFailureRate
        expr: |
          (
            rate(chatbot_jobs_failed_total[5m]) / 
            rate(chatbot_jobs_processed_total[5m])
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          component: worker
        annotations:
          summary: "High job failure rate detected"
          description: "Job failure rate is {{ $value | humanizePercentage }} over the last 5 minutes (threshold: 10%)"

      # Critical job failure rate
      - alert: CriticalJobFailureRate
        expr: |
          (
            rate(chatbot_jobs_failed_total[5m]) / 
            rate(chatbot_jobs_processed_total[5m])
          ) > 0.5
        for: 2m
        labels:
          severity: critical
          component: worker
        annotations:
          summary: "Critical job failure rate detected"
          description: "Job failure rate is {{ $value | humanizePercentage }} over the last 5 minutes (threshold: 50%)"

      # Large queue depth
      - alert: HighQueueDepth
        expr: chatbot_jobs_queue_depth > 100
        for: 10m
        labels:
          severity: warning
          component: queue
        annotations:
          summary: "Job queue depth is high"
          description: "{{ $value }} jobs are waiting in the queue (threshold: 100)"

      # Critical queue depth
      - alert: CriticalQueueDepth
        expr: chatbot_jobs_queue_depth > 500
        for: 5m
        labels:
          severity: critical
          component: queue
        annotations:
          summary: "Job queue depth is critically high"
          description: "{{ $value }} jobs are waiting in the queue (threshold: 500). Workers may be down or overloaded."

      # Worker appears down
      - alert: WorkerDown
        expr: chatbot_worker_healthy == 0
        for: 5m
        labels:
          severity: critical
          component: worker
        annotations:
          summary: "Background worker appears to be down"
          description: "Worker has not processed any jobs in {{ $value }} seconds (threshold: 300 seconds / 5 minutes)"

      # OpenAI API errors
      - alert: HighOpenAIErrorRate
        expr: |
          (
            sum(rate(chatbot_jobs_failed_total{type="openai_request"}[5m])) /
            sum(rate(chatbot_jobs_total{type="openai_request"}[5m]))
          ) > 0.2
        for: 5m
        labels:
          severity: warning
          component: openai
        annotations:
          summary: "High OpenAI API error rate"
          description: "OpenAI API error rate is {{ $value | humanizePercentage }} over the last 5 minutes (threshold: 20%)"

      # Database growing too fast
      - alert: DatabaseGrowthHigh
        expr: |
          rate(chatbot_database_size_bytes[1h]) > 10485760  # 10MB/hour
        for: 30m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Database growing rapidly"
          description: "Database is growing at {{ $value | humanize }}B/hour (threshold: 10MB/hour). Consider archiving old data."

      # No default agent configured
      - alert: NoDefaultAgent
        expr: chatbot_agents_default != 1
        for: 5m
        labels:
          severity: warning
          component: config
        annotations:
          summary: "Invalid default agent configuration"
          description: "Expected exactly 1 default agent, found {{ $value }}. This may cause chat requests to fail."

      # Admin API high error rate
      - alert: AdminAPIHighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{job="chatbot",handler="/admin-api.php",code=~"5.."}[5m])) /
            sum(rate(http_requests_total{job="chatbot",handler="/admin-api.php"}[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: warning
          component: admin_api
        annotations:
          summary: "High Admin API error rate"
          description: "Admin API 5xx error rate is {{ $value | humanizePercentage }} over the last 5 minutes (threshold: 5%)"

      # Webhook processing lag
      - alert: WebhookProcessingLag
        expr: chatbot_webhook_events_total{status="pending"} > 50
        for: 15m
        labels:
          severity: warning
          component: webhooks
        annotations:
          summary: "Webhook events not being processed"
          description: "{{ $value }} webhook events are pending (threshold: 50). Worker may be down or overloaded."

      # File ingestion stuck
      - alert: FileIngestionStuck
        expr: |
          sum(chatbot_jobs_total{type="poll_ingestion_status",status="running"}) > 10
        for: 30m
        labels:
          severity: warning
          component: ingestion
        annotations:
          summary: "Many file ingestion jobs stuck"
          description: "{{ $value }} file ingestion status polling jobs are running for over 30 minutes. Files may be stuck in processing."

      # Memory usage high (requires node_exporter)
      - alert: HighMemoryUsage
        expr: |
          (
            process_resident_memory_bytes{job="chatbot"} / 
            node_memory_MemTotal_bytes
          ) > 0.8
        for: 10m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage detected"
          description: "Process is using {{ $value | humanizePercentage }} of available memory (threshold: 80%)"

      # Disk space low (requires node_exporter)
      - alert: DiskSpaceLow
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/data"} /
            node_filesystem_size_bytes{mountpoint="/data"}
          ) < 0.1
        for: 5m
        labels:
          severity: critical
          component: system
        annotations:
          summary: "Disk space critically low"
          description: "Only {{ $value | humanizePercentage }} disk space remaining on /data (threshold: 10%)"

      # Metrics scrape failures
      - alert: MetricsScrapeFailure
        expr: up{job="chatbot"} == 0
        for: 2m
        labels:
          severity: critical
          component: monitoring
        annotations:
          summary: "Unable to scrape metrics from chatbot"
          description: "Prometheus cannot reach the chatbot metrics endpoint. Application may be down."

      # SSL certificate expiring soon (if using HTTPS monitoring)
      - alert: SSLCertificateExpiringSoon
        expr: |
          probe_ssl_earliest_cert_expiry{job="chatbot_ssl"} - time() < 86400 * 30
        for: 1h
        labels:
          severity: warning
          component: ssl
        annotations:
          summary: "SSL certificate expiring soon"
          description: "SSL certificate will expire in {{ $value | humanizeDuration }}. Renew certificate soon."

      # API response time high
      - alert: HighAPIResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(http_request_duration_seconds_bucket{job="chatbot"}[5m])
          ) > 2
        for: 10m
        labels:
          severity: warning
          component: performance
        annotations:
          summary: "High API response time"
          description: "95th percentile API response time is {{ $value }}s (threshold: 2s)"

  - name: chatbot_capacity
    interval: 60s
    rules:
      # Capacity planning: predict queue growth
      - record: chatbot_queue_growth_rate
        expr: |
          deriv(chatbot_jobs_queue_depth[30m])

      # Capacity planning: job processing throughput
      - record: chatbot_job_throughput
        expr: |
          rate(chatbot_jobs_processed_total[5m])

      # Capacity planning: average job duration
      - record: chatbot_job_duration_avg
        expr: |
          avg(chatbot_job_duration_seconds)
